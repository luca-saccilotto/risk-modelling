{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PD Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dependent Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "loan_data = pd.read_csv(os.path.join(\"..\", \"data\", \"processed\", \"loan_data_0714.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values of a column\n",
    "loan_data[\"loan_status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of observations for each unique value of a variable\n",
    "loan_data[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the proportion of observations for each unique value of a variable\n",
    "loan_data[\"loan_status\"].value_counts() / loan_data[\"loan_status\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary variable to classify the performance of the loan\n",
    "loan_data[\"loan_performance\"] = np.where(loan_data[\"loan_status\"].isin([\"Charged Off\", \n",
    "                                                                        \"Default\",\n",
    "                                                                        \"Does not meet the credit policy. Status:Charged Off\",\n",
    "                                                                        \"Late (31-120 days)\"]), 0, 1)\n",
    "loan_data[\"loan_performance\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split two data frames with inputs and targets and each into a train and test set\n",
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(loan_data.drop(\"loan_performance\", axis = 1), loan_data[\"loan_performance\"], test_size = 0.2, random_state = 42)\n",
    "print(f\"Inputs (Train): {inputs_train.shape}\")\n",
    "print(f\"Target (Train): {targets_train.shape}\\n\")\n",
    "print(f\"Inputs (Test): {inputs_test.shape}\")\n",
    "print(f\"Target (Test): {targets_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Discrete Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the weight of average for discrete variable\n",
    "def woe_discrete(df, variable_name, df_good_bad):\n",
    "    # Concatenate the discrete variable with the input data frame\n",
    "    df = pd.concat([df[variable_name], df_good_bad], axis = 1)\n",
    "    # Group by the discrete variable and calculate the number of observations and mean of the variable\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    # Select the columns that indicates the name of variable and the number and mean of observations\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], \"n_obs\", \"prop_good\"]\n",
    "    # Calculate the proportion of observations for each category\n",
    "    df[\"prop_obs\"] = df[\"n_obs\"] / df[\"n_obs\"].sum()\n",
    "    # Compute the number of \"good\" cases and \"bad\" cases for each category\n",
    "    df[\"n_good\"] = df[\"prop_good\"] * df[\"n_obs\"]\n",
    "    df[\"n_bad\"] = (1 - df[\"prop_good\"]) * df[\"n_obs\"]\n",
    "    # Calculate the proportion of \"good\" and \"bad\" cases\n",
    "    df[\"prop_good\"] = df[\"n_good\"] / df[\"n_good\"].sum()\n",
    "    df[\"prop_bad\"] = df[\"n_bad\"] / df[\"n_bad\"].sum()\n",
    "    # Compute the Weight of Evidence (WoE) for each category\n",
    "    df[\"WoE\"] = np.log(df[\"prop_good\"] / df[\"prop_bad\"])\n",
    "    # Sort the data frame by WoE\n",
    "    df = df.sort_values([\"WoE\"])\n",
    "    # Reset the index of the data frame\n",
    "    df = df.reset_index(drop = True)\n",
    "    # Calculate the absolute difference in \"prop_good\" and \"WoE\" between consecutive categories\n",
    "    df[\"diff_prop_good\"] = df[\"prop_good\"].diff().abs()\n",
    "    df[\"diff_WoE\"] = df[\"WoE\"].diff().abs()\n",
    "    # Compute the Information Value (IV) for the entire variable\n",
    "    df[\"IV\"] = (df[\"prop_good\"] - df[\"prop_bad\"]) * df[\"WoE\"]\n",
    "    df[\"IV\"] = df[\"IV\"].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that displays results\n",
    "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
    "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
    "    y = df_WoE[\"WoE\"]\n",
    "    plt.figure(figsize = (12, 3))\n",
    "    sns.set_style(\"white\")\n",
    "    plt.plot(x, y, marker = \"o\", linestyle = \"--\", color = \"k\")\n",
    "    plt.xlabel(df_WoE.columns[0], fontsize = 12)\n",
    "    plt.ylabel(\"Weight of Evidence\", fontsize = 12)\n",
    "    plt.xticks(rotation = rotation_of_x_axis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary arguments\n",
    "df_inputs = inputs_train\n",
    "df_targets = targets_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Grade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"grade\"\n",
    "df_temp = woe_discrete(df_inputs, \"grade\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Home Ownership**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"home_ownership\"\n",
    "df_temp = woe_discrete(df_inputs, \"home_ownership\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new discrete variable to combine some of the categories\n",
    "df_inputs[\"home_ownership:RENT_OTHER_NONE_ANY\"] = sum([df_inputs[\"home_ownership:RENT\"],\n",
    "                                                       df_inputs[\"home_ownership:OTHER\"],\n",
    "                                                       df_inputs[\"home_ownership:NONE\"],\n",
    "                                                       df_inputs[\"home_ownership:ANY\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **State Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"addr_state\"\n",
    "df_temp = woe_discrete(df_inputs, \"addr_state\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the column exists in the data frame and if it does not add it\n",
    "if [\"addr_state:ND\"] in df_inputs.columns.values:\n",
    "    pass\n",
    "else:\n",
    "    df_inputs[\"addr_state:ND\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the weight of evidence values\n",
    "plot_by_woe(df_temp.iloc[2: -2, : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categories using weight of evidence values and set \"IA_NV_HI_ID_AL_FL\" as the reference one\n",
    "df_inputs[\"addr_state:ND_NE_IA_NV_FL_HI_AL\"] = sum([df_inputs[\"addr_state:ND\"],\n",
    "                                                    df_inputs[\"addr_state:NE\"],\n",
    "                                                    df_inputs[\"addr_state:IA\"],\n",
    "                                                    df_inputs[\"addr_state:NV\"],\n",
    "                                                    df_inputs[\"addr_state:FL\"],\n",
    "                                                    df_inputs[\"addr_state:HI\"],\n",
    "                                                    df_inputs[\"addr_state:AL\"]])\n",
    "\n",
    "df_inputs[\"addr_state:NM_VA\"] = sum([df_inputs[\"addr_state:NM\"], df_inputs[\"addr_state:VA\"]])\n",
    "\n",
    "df_inputs[\"addr_state:OK_TN_MO_LA_MD_NC\"] = sum([df_inputs[\"addr_state:OK\"],\n",
    "                                                 df_inputs[\"addr_state:TN\"],\n",
    "                                                 df_inputs[\"addr_state:MO\"],\n",
    "                                                 df_inputs[\"addr_state:LA\"],\n",
    "                                                 df_inputs[\"addr_state:MD\"],\n",
    "                                                 df_inputs[\"addr_state:NC\"]])\n",
    "\n",
    "df_inputs[\"addr_state:UT_KY_AZ_NJ\"] = sum([df_inputs[\"addr_state:UT\"],\n",
    "                                           df_inputs[\"addr_state:KY\"],\n",
    "                                           df_inputs[\"addr_state:AZ\"],\n",
    "                                           df_inputs[\"addr_state:NJ\"]])\n",
    "\n",
    "df_inputs[\"addr_state:AR_MI_PA_OH_MN\"] = sum([df_inputs[\"addr_state:AR\"],\n",
    "                                              df_inputs[\"addr_state:MI\"],\n",
    "                                              df_inputs[\"addr_state:PA\"],\n",
    "                                              df_inputs[\"addr_state:OH\"],\n",
    "                                              df_inputs[\"addr_state:MN\"]])\n",
    "\n",
    "df_inputs[\"addr_state:RI_MA_DE_SD_IN\"] = sum([df_inputs[\"addr_state:RI\"],\n",
    "                                              df_inputs[\"addr_state:MA\"],\n",
    "                                              df_inputs[\"addr_state:DE\"],\n",
    "                                              df_inputs[\"addr_state:SD\"],\n",
    "                                              df_inputs[\"addr_state:IN\"]])\n",
    "\n",
    "df_inputs[\"addr_state:GA_WA_OR\"] = sum([df_inputs[\"addr_state:GA\"],\n",
    "                                        df_inputs[\"addr_state:WA\"],\n",
    "                                        df_inputs[\"addr_state:OR\"]])\n",
    "\n",
    "df_inputs[\"addr_state:WI_MT\"] = sum([df_inputs[\"addr_state:WI\"],\n",
    "                                     df_inputs[\"addr_state:MT\"]])\n",
    "\n",
    "df_inputs[\"addr_state:IL_CT\"] = sum([df_inputs[\"addr_state:IL\"],\n",
    "                                     df_inputs[\"addr_state:CT\"]])\n",
    "\n",
    "df_inputs[\"addr_state:KS_SC_CO_VT_AK_MS\"] = sum([df_inputs[\"addr_state:KS\"],\n",
    "                                                 df_inputs[\"addr_state:SC\"],\n",
    "                                                 df_inputs[\"addr_state:CO\"],\n",
    "                                                 df_inputs[\"addr_state:VT\"],\n",
    "                                                 df_inputs[\"addr_state:AK\"],\n",
    "                                                 df_inputs[\"addr_state:MS\"]])\n",
    "\n",
    "df_inputs[\"addr_state:WV_NH_WY_DC_ME_ID\"] = sum([df_inputs[\"addr_state:WV\"],\n",
    "                                                 df_inputs[\"addr_state:NH\"],\n",
    "                                                 df_inputs[\"addr_state:WY\"],\n",
    "                                                 df_inputs[\"addr_state:DC\"],\n",
    "                                                 df_inputs[\"addr_state:ME\"],\n",
    "                                                 df_inputs[\"addr_state:ID\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Verification Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"verification_status\"\n",
    "df_temp = woe_discrete(df_inputs, \"verification_status\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"purpose\"\n",
    "df_temp = woe_discrete(df_inputs, \"purpose\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categories using weight of evidence values and set \"purpose:e_sb_w_re_m_h\" as the reference one\n",
    "df_inputs[\"purpose:e_sb_w_re_m_h\"] = sum([df_inputs[\"purpose:educational\"],\n",
    "                                          df_inputs[\"purpose:small_business\"],\n",
    "                                          df_inputs[\"purpose:wedding\"],\n",
    "                                          df_inputs[\"purpose:renewable_energy\"],\n",
    "                                          df_inputs[\"purpose:moving\"],\n",
    "                                          df_inputs[\"purpose:house\"]])\n",
    "\n",
    "df_inputs[\"purpose:o_m_v\"] = sum([df_inputs[\"purpose:other\"],\n",
    "                                  df_inputs[\"purpose:medical\"],\n",
    "                                  df_inputs[\"purpose:vacation\"]])\n",
    "\n",
    "df_inputs[\"purpose:mp_c_hi\"] = sum([df_inputs[\"purpose:major_purchase\"],\n",
    "                                    df_inputs[\"purpose:car\"],\n",
    "                                    df_inputs[\"purpose:home_improvement\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **List Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"initial_list_status\"\n",
    "df_temp = woe_discrete(df_inputs, \"initial_list_status\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Continuos Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for ordered discrete and continuous variables\n",
    "def woe_ordered_continuous(df, variable_name, df_good_bad):\n",
    "    # Concatenate the discrete variable with the input data frame\n",
    "    df = pd.concat([df[variable_name], df_good_bad], axis = 1)\n",
    "    # Group by the discrete variable and calculate the number of observations and mean of the variable\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
    "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
    "    # Select the columns that indicates the name of variable and the number and mean of observations\n",
    "    df = df.iloc[:, [0, 1, 3]]\n",
    "    df.columns = [df.columns.values[0], \"n_obs\", \"prop_good\"]\n",
    "    # Calculate the proportion of observations for each category\n",
    "    df[\"prop_obs\"] = df[\"n_obs\"] / df[\"n_obs\"].sum()\n",
    "    # Compute the number of \"good\" cases and \"bad\" cases for each category\n",
    "    df[\"n_good\"] = df[\"prop_good\"] * df[\"n_obs\"]\n",
    "    df[\"n_bad\"] = (1 - df[\"prop_good\"]) * df[\"n_obs\"]\n",
    "    # Calculate the proportion of \"good\" and \"bad\" cases\n",
    "    df[\"prop_good\"] = df[\"n_good\"] / df[\"n_good\"].sum()\n",
    "    df[\"prop_bad\"] = df[\"n_bad\"] / df[\"n_bad\"].sum()\n",
    "    # Compute the Weight of Evidence (WoE) for each category\n",
    "    df[\"WoE\"] = np.log(df[\"prop_good\"] / df[\"prop_bad\"])\n",
    "    # Calculate the absolute difference in \"prop_good\" and \"WoE\" between consecutive categories\n",
    "    df[\"diff_prop_good\"] = df[\"prop_good\"].diff().abs()\n",
    "    df[\"diff_WoE\"] = df[\"WoE\"].diff().abs()\n",
    "    # Compute the Information Value (IV) for the entire variable\n",
    "    df[\"IV\"] = (df[\"prop_good\"] - df[\"prop_bad\"]) * df[\"WoE\"]\n",
    "    df[\"IV\"] = df[\"IV\"].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Term**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"term_int\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"term_int\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"60\" as the reference category\n",
    "df_inputs[\"term:36\"] = np.where((df_inputs[\"term_int\"] == 36), 1, 0)\n",
    "df_inputs[\"term:60\"] = np.where((df_inputs[\"term_int\"] == 60), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Employment Length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"emp_length\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"emp_length\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories and set \"0\" as the reference one\n",
    "df_inputs[\"emp_length:0\"] = np.where(df_inputs[\"emp_length\"].isin([0]), 1, 0)\n",
    "df_inputs[\"emp_length:1\"] = np.where(df_inputs[\"emp_length\"].isin([1]), 1, 0)\n",
    "df_inputs[\"emp_length:2-4\"] = np.where(df_inputs[\"emp_length\"].isin(range(2, 5)), 1, 0)\n",
    "df_inputs[\"emp_length:5-6\"] = np.where(df_inputs[\"emp_length\"].isin(range(5, 7)), 1, 0)\n",
    "df_inputs[\"emp_length:7-9\"] = np.where(df_inputs[\"emp_length\"].isin(range(7, 10)), 1, 0)\n",
    "df_inputs[\"emp_length:10\"] = np.where(df_inputs[\"emp_length\"].isin([10]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Issue Months**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"mths_issue_d\"\n",
    "df_inputs[\"mths_issue_d_factor\"] = pd.cut(df_inputs[\"mths_issue_d\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"mths_issue_d_factor\", df_targets)\n",
    "plot_by_woe(df_temp.iloc[3: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"mths_issue_d:<38\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(38)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:38-39\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(38, 40)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:40-41\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(40, 42)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:42-48\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(42, 49)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:49-52\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(49, 53)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:53-64\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(53, 65)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:65-84\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(65, 85)), 1, 0)\n",
    "df_inputs[\"mths_issue_d:>84\"] = np.where(df_inputs[\"mths_issue_d\"].isin(range(85, 125)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interest Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"int_rate\"\n",
    "df_inputs[\"int_rate_factor\"] = pd.cut(df_inputs[\"int_rate\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"int_rate_factor\", df_targets)\n",
    "plot_by_woe(df_temp.iloc[3: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"int_rate:<9.548\"] = np.where((df_inputs[\"int_rate\"] <= 9.548), 1, 0)\n",
    "df_inputs[\"int_rate:9.548-12.025\"] = np.where((df_inputs[\"int_rate\"] > 9.548) & (df_inputs[\"int_rate\"] <= 12.025), 1, 0)\n",
    "df_inputs[\"int_rate:12.025-15.74\"] = np.where((df_inputs[\"int_rate\"] > 12.025) & (df_inputs[\"int_rate\"] <= 15.74), 1, 0)\n",
    "df_inputs[\"int_rate:15.74-20.281\"] = np.where((df_inputs[\"int_rate\"] > 15.74) & (df_inputs[\"int_rate\"] <= 20.281), 1, 0)\n",
    "df_inputs[\"int_rate:>20.281\"] = np.where((df_inputs[\"int_rate\"] > 20.281), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Funded Amount**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"funded_amnt\"\n",
    "df_inputs[\"funded_amnt_factor\"] = pd.cut(df_inputs[\"funded_amnt\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"funded_amnt_factor\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Credit Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"months_cr_line\"\n",
    "df_inputs[\"months_cr_line_factor\"] = pd.cut(df_inputs[\"months_cr_line\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"months_cr_line_factor\", df_targets)\n",
    "plot_by_woe(df_temp.iloc[6: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"months_cr_line:<140\"] = np.where(df_inputs[\"months_cr_line\"].isin(range(140)), 1, 0)\n",
    "df_inputs[\"months_cr_line:141-164\"] = np.where(df_inputs[\"months_cr_line\"].isin(range(140, 165)), 1, 0)\n",
    "df_inputs[\"months_cr_line:165-247\"] = np.where(df_inputs[\"months_cr_line\"].isin(range(165, 248)), 1, 0)\n",
    "df_inputs[\"months_cr_line:248-270\"] = np.where(df_inputs[\"months_cr_line\"].isin(range(248, 271)), 1, 0)\n",
    "df_inputs[\"months_cr_line:271-352\"] = np.where(df_inputs[\"months_cr_line\"].isin(range(271, 353)), 1, 0)\n",
    "df_inputs[\"months_cr_line:>352\"] = np.where(df_inputs[\"months_cr_line\"].isin(range(353, int(df_inputs[\"months_cr_line\"].max()))), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Delinquency (2 Years)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"delinq_2yrs\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"delinq_2yrs\", df_targets)\n",
    "plot_by_woe(df_temp.iloc[6: , : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"delinq_2yrs:0\"] = np.where((df_inputs[\"delinq_2yrs\"] == 0), 1, 0)\n",
    "df_inputs[\"delinq_2yrs:1-3\"] = np.where((df_inputs[\"delinq_2yrs\"] >= 1) & (df_inputs[\"delinq_2yrs\"] <= 3), 1, 0)\n",
    "df_inputs[\"delinq_2yrs:>=4\"] = np.where((df_inputs[\"delinq_2yrs\"] >= 9), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inquiries Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"inq_last_6mths\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"inq_last_6mths\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"inq_last_6mths:0\"] = np.where((df_inputs[\"inq_last_6mths\"] == 0), 1, 0)\n",
    "df_inputs[\"inq_last_6mths:1-2\"] = np.where((df_inputs[\"inq_last_6mths\"] >= 1) & (df_inputs[\"inq_last_6mths\"] <= 2), 1, 0)\n",
    "df_inputs[\"inq_last_6mths:3-6\"] = np.where((df_inputs[\"inq_last_6mths\"] >= 3) & (df_inputs[\"inq_last_6mths\"] <= 6), 1, 0)\n",
    "df_inputs[\"inq_last_6mths:>6\"] = np.where((df_inputs[\"inq_last_6mths\"] > 6), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Open Accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"open_acc\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"open_acc\", df_targets)\n",
    "plot_by_woe(df_temp.iloc[ : 40, :], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"open_acc:0\"] = np.where((df_inputs[\"open_acc\"] == 0), 1, 0)\n",
    "df_inputs[\"open_acc:1-3\"] = np.where((df_inputs[\"open_acc\"] >= 1) & (df_inputs[\"open_acc\"] <= 3), 1, 0)\n",
    "df_inputs[\"open_acc:4-12\"] = np.where((df_inputs[\"open_acc\"] >= 4) & (df_inputs[\"open_acc\"] <= 12), 1, 0)\n",
    "df_inputs[\"open_acc:13-17\"] = np.where((df_inputs[\"open_acc\"] >= 13) & (df_inputs[\"open_acc\"] <= 17), 1, 0)\n",
    "df_inputs[\"open_acc:18-22\"] = np.where((df_inputs[\"open_acc\"] >= 18) & (df_inputs[\"open_acc\"] <= 22), 1, 0)\n",
    "df_inputs[\"open_acc:23-25\"] = np.where((df_inputs[\"open_acc\"] >= 23) & (df_inputs[\"open_acc\"] <= 25), 1, 0)\n",
    "df_inputs[\"open_acc:26-30\"] = np.where((df_inputs[\"open_acc\"] >= 26) & (df_inputs[\"open_acc\"] <= 30), 1, 0)\n",
    "df_inputs[\"open_acc:>=31\"] = np.where((df_inputs[\"open_acc\"] >= 31), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Public Records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"pub_rec\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"pub_rec\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"pub_rec:0-2\"] = np.where((df_inputs[\"pub_rec\"] >= 0) & (df_inputs[\"pub_rec\"] <= 2), 1, 0)\n",
    "df_inputs[\"pub_rec:3-4\"] = np.where((df_inputs[\"pub_rec\"] >= 3) & (df_inputs[\"pub_rec\"] <= 4), 1, 0)\n",
    "df_inputs[\"pub_rec:>=5\"] = np.where((df_inputs[\"pub_rec\"] >= 5), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"total_acc\"\n",
    "df_inputs[\"total_acc_factor\"] = pd.cut(df_inputs[\"total_acc\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"total_acc_factor\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"total_acc:<=27\"] = np.where((df_inputs[\"total_acc\"] <= 27), 1, 0)\n",
    "df_inputs[\"total_acc:28-51\"] = np.where((df_inputs[\"total_acc\"] >= 28) & (df_inputs[\"total_acc\"] <= 51), 1, 0)\n",
    "df_inputs[\"total_acc:>=52\"] = np.where((df_inputs[\"total_acc\"] >= 52), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Delinquent Account**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"acc_now_delinq\"\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"acc_now_delinq\", df_targets)\n",
    "plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"acc_now_delinq:0\"] = np.where((df_inputs[\"acc_now_delinq\"] == 0), 1, 0)\n",
    "df_inputs[\"acc_now_delinq:>=1\"] = np.where((df_inputs[\"acc_now_delinq\"] >= 1), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Total Revolving Credit Limit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"total_rev_hi_lim\"\n",
    "df_inputs[\"total_rev_hi_lim_factor\"] = pd.cut(df_inputs[\"total_rev_hi_lim\"], 2000)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 2000 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"total_rev_hi_lim_factor\", df_targets)\n",
    "plot_by_woe(df_temp.iloc[: 50, : ], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"total_rev_hi_lim:<=5K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] <= 5000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:5K-10K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 5000) & (df_inputs[\"total_rev_hi_lim\"] <= 10000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:10K-20K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 10000) & (df_inputs[\"total_rev_hi_lim\"] <= 20000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:20K-30K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 20000) & (df_inputs[\"total_rev_hi_lim\"] <= 30000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:30K-40K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 30000) & (df_inputs[\"total_rev_hi_lim\"] <= 40000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:40K-55K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 40000) & (df_inputs[\"total_rev_hi_lim\"] <= 55000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:55K-95K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 55000) & (df_inputs[\"total_rev_hi_lim\"] <= 95000), 1, 0)\n",
    "df_inputs[\"total_rev_hi_lim:>95K\"] = np.where((df_inputs[\"total_rev_hi_lim\"] > 95000), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Installment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"installment\"\n",
    "df_inputs[\"installment_factor\"] = pd.cut(df_inputs[\"installment\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"installment_factor\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Annual Income**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"annual_inc\"\n",
    "df_inputs = df_inputs.loc[df_inputs[\"annual_inc\"] <= 140000, :]\n",
    "df_inputs[\"annual_inc_factor\"] = pd.cut(df_inputs[\"annual_inc\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"annual_inc_factor\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories considering that WoE is monotonically decreasing with income:\n",
    "df_inputs[\"annual_inc:<20K\"] = np.where((df_inputs[\"annual_inc\"] <= 20000), 1, 0)\n",
    "df_inputs[\"annual_inc:20K-30K\"] = np.where((df_inputs[\"annual_inc\"] > 20000) & (df_inputs[\"annual_inc\"] <= 30000), 1, 0)\n",
    "df_inputs[\"annual_inc:30K-40K\"] = np.where((df_inputs[\"annual_inc\"] > 30000) & (df_inputs[\"annual_inc\"] <= 40000), 1, 0)\n",
    "df_inputs[\"annual_inc:40K-50K\"] = np.where((df_inputs[\"annual_inc\"] > 40000) & (df_inputs[\"annual_inc\"] <= 50000), 1, 0)\n",
    "df_inputs[\"annual_inc:50K-60K\"] = np.where((df_inputs[\"annual_inc\"] > 50000) & (df_inputs[\"annual_inc\"] <= 60000), 1, 0)\n",
    "df_inputs[\"annual_inc:60K-70K\"] = np.where((df_inputs[\"annual_inc\"] > 60000) & (df_inputs[\"annual_inc\"] <= 70000), 1, 0)\n",
    "df_inputs[\"annual_inc:70K-80K\"] = np.where((df_inputs[\"annual_inc\"] > 70000) & (df_inputs[\"annual_inc\"] <= 80000), 1, 0)\n",
    "df_inputs[\"annual_inc:80K-90K\"] = np.where((df_inputs[\"annual_inc\"] > 80000) & (df_inputs[\"annual_inc\"] <= 90000), 1, 0)\n",
    "df_inputs[\"annual_inc:90K-100K\"] = np.where((df_inputs[\"annual_inc\"] > 90000) & (df_inputs[\"annual_inc\"] <= 100000), 1, 0)\n",
    "df_inputs[\"annual_inc:100K-120K\"] = np.where((df_inputs[\"annual_inc\"] > 100000) & (df_inputs[\"annual_inc\"] <= 120000), 1, 0)\n",
    "df_inputs[\"annual_inc:120K-140K\"] = np.where((df_inputs[\"annual_inc\"] > 120000) & (df_inputs[\"annual_inc\"] <= 140000), 1, 0)\n",
    "df_inputs[\"annual_inc:>140K\"] = np.where((df_inputs[\"annual_inc\"] > 140000), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Delinquency Months**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"mths_since_last_delinq\"\n",
    "df_temp = df_inputs[pd.notnull(df_inputs[\"mths_since_last_delinq\"])]\n",
    "# Create one category for missing values and do fine and coarse classing for the rest\n",
    "df_temp[\"mths_since_last_delinq_factor\"] = pd.cut(df_temp[\"mths_since_last_delinq\"], 50)\n",
    "df_temp = woe_ordered_continuous(df_temp, \"mths_since_last_delinq_factor\", df_targets[df_temp.index])\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"mths_since_last_delinq:Missing\"] = np.where((df_inputs[\"mths_since_last_delinq\"].isnull()), 1, 0)\n",
    "df_inputs[\"mths_since_last_delinq:0-3\"] = np.where((df_inputs[\"mths_since_last_delinq\"] >= 0) & (df_inputs[\"mths_since_last_delinq\"] <= 3), 1, 0)\n",
    "df_inputs[\"mths_since_last_delinq:4-30\"] = np.where((df_inputs[\"mths_since_last_delinq\"] >= 4) & (df_inputs[\"mths_since_last_delinq\"] <= 30), 1, 0)\n",
    "df_inputs[\"mths_since_last_delinq:31-56\"] = np.where((df_inputs[\"mths_since_last_delinq\"] >= 31) & (df_inputs[\"mths_since_last_delinq\"] <= 56), 1, 0)\n",
    "df_inputs[\"mths_since_last_delinq:>=57\"] = np.where((df_inputs[\"mths_since_last_delinq\"] >= 57), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Debt-to-Income Ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"dti\"\n",
    "df_temp = df_inputs.loc[df_inputs[\"dti\"] <= 35, : ]\n",
    "df_inputs[\"dti_factor\"] = pd.cut(df_inputs[\"dti\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 100 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_inputs, \"dti_factor\", df_targets)\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"dti:<=1.4\"] = np.where((df_inputs[\"dti\"] <= 1.4), 1, 0)\n",
    "df_inputs[\"dti:1.4-3.5\"] = np.where((df_inputs[\"dti\"] > 1.4) & (df_inputs[\"dti\"] <= 3.5), 1, 0)\n",
    "df_inputs[\"dti:3.5-7.7\"] = np.where((df_inputs[\"dti\"] > 3.5) & (df_inputs[\"dti\"] <= 7.7), 1, 0)\n",
    "df_inputs[\"dti:7.7-10.5\"] = np.where((df_inputs[\"dti\"] > 7.7) & (df_inputs[\"dti\"] <= 10.5), 1, 0)\n",
    "df_inputs[\"dti:10.5-16.1\"] = np.where((df_inputs[\"dti\"] > 10.5) & (df_inputs[\"dti\"] <= 16.1), 1, 0)\n",
    "df_inputs[\"dti:16.1-20.3\"] = np.where((df_inputs[\"dti\"] > 16.1) & (df_inputs[\"dti\"] <= 20.3), 1, 0)\n",
    "df_inputs[\"dti:20.3-21.7\"] = np.where((df_inputs[\"dti\"] > 20.3) & (df_inputs[\"dti\"] <= 21.7), 1, 0)\n",
    "df_inputs[\"dti:21.7-22.4\"] = np.where((df_inputs[\"dti\"] > 21.7) & (df_inputs[\"dti\"] <= 22.4), 1, 0)\n",
    "df_inputs[\"dti:22.4-35\"] = np.where((df_inputs[\"dti\"] > 22.4) & (df_inputs[\"dti\"] <= 35), 1, 0)\n",
    "df_inputs[\"dti:>35\"] = np.where((df_inputs[\"dti\"] > 35), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Last Records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable: \"mths_since_last_record\"\n",
    "# Create one category for missing values and do fine and coarse classing for the rest\n",
    "df_temp = df_inputs[pd.notnull(df_inputs[\"mths_since_last_record\"])]\n",
    "df_temp[\"mths_since_last_record_factor\"] = pd.cut(df_temp[\"mths_since_last_record\"], 50)\n",
    "# Use the \"cut\" method to do fine-classing and split the variable into 50 categories by its values\n",
    "df_temp = woe_ordered_continuous(df_temp, \"mths_since_last_record_factor\", df_targets[df_temp.index])\n",
    "plot_by_woe(df_temp, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the following categories:\n",
    "df_inputs[\"mths_since_last_record:Missing\"] = np.where((df_inputs[\"mths_since_last_record\"].isnull()), 1, 0)\n",
    "df_inputs[\"mths_since_last_record:0-2\"] = np.where((df_inputs[\"mths_since_last_record\"] >= 0) & (df_inputs[\"mths_since_last_record\"] <= 2), 1, 0)\n",
    "df_inputs[\"mths_since_last_record:3-20\"] = np.where((df_inputs[\"mths_since_last_record\"] >= 3) & (df_inputs[\"mths_since_last_record\"] <= 20), 1, 0)\n",
    "df_inputs[\"mths_since_last_record:21-31\"] = np.where((df_inputs[\"mths_since_last_record\"] >= 21) & (df_inputs[\"mths_since_last_record\"] <= 31), 1, 0)\n",
    "df_inputs[\"mths_since_last_record:32-80\"] = np.where((df_inputs[\"mths_since_last_record\"] >= 32) & (df_inputs[\"mths_since_last_record\"] <= 80), 1, 0)\n",
    "df_inputs[\"mths_since_last_record:81-86\"] = np.where((df_inputs[\"mths_since_last_record\"] >= 81) & (df_inputs[\"mths_since_last_record\"] <= 86), 1, 0)\n",
    "df_inputs[\"mths_since_last_record:>86\"] = np.where((df_inputs[\"mths_since_last_record\"] > 86), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data set\n",
    "inputs_train = df_inputs\n",
    "path = os.path.join(\"..\", \"data\", \"processed\", \"train\")\n",
    "os.makedirs(path, exist_ok = True)\n",
    "inputs_train.to_csv(os.path.join(path, \"inputs_train.csv\"))\n",
    "targets_train.to_csv(os.path.join(path, \"targets_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save testing data set\n",
    "inputs_test = df_inputs\n",
    "path = os.path.join(\"..\", \"data\", \"processed\", \"test\")\n",
    "os.makedirs(path, exist_ok = True)\n",
    "inputs_test.to_csv(os.path.join(path, \"inputs_test.csv\"))\n",
    "targets_test.to_csv(os.path.join(path, \"targets_test.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
